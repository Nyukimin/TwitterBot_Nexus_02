# 完了したタスクと今後の課題

## 完了したタスク
- `_extract_tweet_info` 関数の `reply_bot/fetch.py` への統合が完了しました。
- 重複するリプライIDをスキップするロジックが実装されました。
- 抽出結果を `extracted_tweets.csv` ファイルに追記するロジックが実装されました。
- `debug_page_source_NNN.html` (3桁の連番) の形式でHTMLソースを保存するよう変更されました。
- スクロール量が、ウィンドウの高さの80%分をスクロールすることで20%の重複を目指すように初期調整されました。

## 今後の課題
- スクロール量の適応的調整（1回のページリロード分の20%重複）の調査と実装が必要です。

# 現状の問題点

## 1. HTML解析セレクタの不正確さ
`reply_bot/fetch.py` 内のリプライ情報抽出セレクタが、Xの通知ページの実際のHTML構造と合致していないため、リプライ情報の抽出に失敗しています。これは、これまで参照していた `source.html` が、実際にSeleniumが取得するページソースと異なっていたことが一因です。

## 2. リプライが0件で取得される問題
上記のセレクタの不正確さにより、`fetch_replies` 関数がリプライを全く検出できていません。

## 3. `tweet_datetime` の日付比較エラー（解決済み）
`offset-naive` と `offset-aware` の `datetime` オブジェクトの比較エラーが発生していましたが、これは `reply_bot/fetch.py` の前回の修正で対応済みです。この修正が正しく機能するかを確認する必要があります。 